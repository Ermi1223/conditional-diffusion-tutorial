{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ermi1223/conditional-diffusion-tutorial/blob/main/conditional_diffusion_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conditional diffusion model**"
      ],
      "metadata": {
        "id": "vd81w1NPCnjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Setup GPU Acceleration**"
      ],
      "metadata": {
        "id": "Pc5b_YQNE_C-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First cell: Setup GPU\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x40xfLsnCnum",
        "outputId": "74c699e2-34c6-4ec7-ec29-0625d020f63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Install Required Packages**"
      ],
      "metadata": {
        "id": "UMK1GOsDFKct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Second cell: Install dependencies\n",
        "!pip install torch torchvision matplotlib tqdm ipywidgets\n",
        "!pip install diffusers transformers\n",
        "!pip install diffusers transformers accelerate\n",
        "!pip install pytorch-fid torch-fidelity scipy ftfy regex\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install torch-fidelity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEm_OekCEAbZ",
        "outputId": "d8190236-975d-4a9e-8d3b-e5af4588c3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.24.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.33.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.6.15)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.33.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Collecting pytorch-fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torch-fidelity in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (11.2.1)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.1->pytorch-fid) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.2)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy, pytorch-fid\n",
            "Successfully installed ftfy-6.3.1 pytorch-fid-0.3.0\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-3a_cbu9g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-3a_cbu9g\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=3dbe0015148fb8cac2a41d21d0d34a6aa399f2b21356551c609b8a66947eef66\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aa2dbmr1/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n",
            "Requirement already satisfied: torch-fidelity in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.15.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Import Libraries and Configuration**"
      ],
      "metadata": {
        "id": "vnvN-XQtFVca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Libraries and Config\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from diffusers import DDPMScheduler\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from PIL import Image\n",
        "from torch_fidelity import calculate_metrics\n",
        "# Configuration\n",
        "IMG_SIZE = 32\n",
        "BATCH_SIZE = 64\n",
        "TIMESTEPS = 500  # Reduced for faster training\n",
        "NUM_EPOCHS = 10  # Reduced for demonstration\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7siIUfOCECCO",
        "outputId": "13fecf16-544e-417d-fe56-e71dc693d467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.6.0+cu124\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Dataset Preparation**"
      ],
      "metadata": {
        "id": "RmWD8ae3HUGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CLIP once (global)\n",
        "clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE).eval()\n",
        "\n",
        "# Precompute embeddings (only 10 CIFAR classes)\n",
        "class_to_text = {\n",
        "    0: \"an airplane flying in the sky\",\n",
        "    1: \"an automobile on the road\",\n",
        "    2: \"a bird perched on a branch\",\n",
        "    3: \"a cat sitting on a windowsill\",\n",
        "    4: \"a deer in the forest\",\n",
        "    5: \"a dog playing in the park\",\n",
        "    6: \"a frog on a lily pad\",\n",
        "    7: \"a horse running in a field\",\n",
        "    8: \"a ship sailing on the ocean\",\n",
        "    9: \"a truck driving on the highway\"\n",
        "}\n",
        "\n",
        "precomputed_embeddings = {}\n",
        "for label, text in class_to_text.items():\n",
        "    inputs = clip_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        text_emb = clip_text_encoder(**inputs).last_hidden_state.mean(dim=1)\n",
        "    precomputed_embeddings[label] = text_emb.squeeze(0).cpu()  # move to CPU for safety\n",
        "\n",
        "# Dataset Class\n",
        "class CIFAR10Conditional(Dataset):\n",
        "    def __init__(self, root, train=True):\n",
        "        super().__init__()\n",
        "        self.cifar = datasets.CIFAR10(\n",
        "            root=root, train=train, download=True,\n",
        "            transform=transforms.Compose([\n",
        "                transforms.Resize(IMG_SIZE),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.5], [0.5])\n",
        "            ])\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cifar)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.cifar[idx]\n",
        "        text_emb = precomputed_embeddings[label]\n",
        "        return img, label, text_emb\n",
        "\n",
        "# Load Data\n",
        "train_dataset = CIFAR10Conditional(root='./data', train=True)\n",
        "test_dataset = CIFAR10Conditional(root='./data', train=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmn5rWvmHYnE",
        "outputId": "470b6c04-82ca-44c8-b75c-706b539b3504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 50000\n",
            "Test dataset size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KP97GOvgjy7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Conditional(Dataset):\n",
        "    def __init__(self, root, train=True):\n",
        "        super().__init__()\n",
        "        self.cifar = datasets.CIFAR10(root=root, train=train, download=True,\n",
        "                                      transform=transforms.Compose([\n",
        "                                          transforms.Resize(IMG_SIZE),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.5], [0.5])\n",
        "                                      ]))\n",
        "        self.prompt_templates = {\n",
        "            0: [\"a red airplane in the sky\", \"an airplane flying over mountains\"],\n",
        "            1: [\"a black car on the road\", \"a sports car racing\"],\n",
        "            2: [\"a bird perched on a tree\", \"a bird flying over water\"],\n",
        "            3: [\"a cat sitting on a sofa\", \"a kitten near a window\"],\n",
        "            4: [\"a deer in the forest\", \"a deer running in snow\"],\n",
        "            5: [\"a dog playing in grass\", \"a puppy on the beach\"],\n",
        "            6: [\"a frog on a lily pad\", \"a green frog in a pond\"],\n",
        "            7: [\"a horse running in the field\", \"a horse in the mountains\"],\n",
        "            8: [\"a ship sailing at sunset\", \"a boat on the ocean\"],\n",
        "            9: [\"a truck on a highway\", \"a delivery truck in rain\"]\n",
        "        }\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        self.text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cifar)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.cifar[idx]\n",
        "        text = np.random.choice(self.prompt_templates[label])\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            text_emb = self.text_encoder(**inputs).last_hidden_state.mean(dim=1)\n",
        "        return img, label, text_emb.squeeze(0).cpu()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=0)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "jKZxRL-cjzEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71dfd347-af74-4974-bbd0-70e7e83084ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 50000\n",
            "Test dataset size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Model Architecture**"
      ],
      "metadata": {
        "id": "7R1QI8ysEucB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, t):\n",
        "        half_dim = self.dim // 2\n",
        "        emb = torch.exp(torch.arange(half_dim, device=DEVICE) * -(np.log(10000.0) / (half_dim - 1)))\n",
        "        emb = t[:, None] * emb[None, :]\n",
        "        return torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "\n",
        "class ConditionalBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_dim, cond_dim):\n",
        "        super().__init__()\n",
        "        self.time_layer = nn.Sequential(nn.Linear(time_dim, out_ch), nn.SiLU())\n",
        "        self.cond_layer = nn.Sequential(nn.Linear(cond_dim, out_ch), nn.SiLU())\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.GroupNorm(8, out_ch), nn.SiLU(),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.GroupNorm(8, out_ch), nn.SiLU()\n",
        "        )\n",
        "        self.residual = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb, c_emb):\n",
        "        h = self.conv(x) + self.residual(x)\n",
        "        scale = self.time_layer(t_emb) + self.cond_layer(c_emb)\n",
        "        scale = scale.view(scale.shape[0], scale.shape[1], 1, 1)\n",
        "        return h * scale\n",
        "\n",
        "class ConditionalUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        time_dim = 128\n",
        "        cond_dim = 512\n",
        "\n",
        "        self.time_mlp = nn.Sequential(TimeEmbedding(time_dim), nn.Linear(time_dim, time_dim), nn.SiLU(), nn.Linear(time_dim, time_dim))\n",
        "        self.cond_proj = nn.Sequential(nn.Linear(cond_dim, cond_dim), nn.SiLU(), nn.Linear(cond_dim, cond_dim))\n",
        "\n",
        "        self.down1 = ConditionalBlock(3, 32, time_dim, cond_dim)\n",
        "        self.down2 = ConditionalBlock(32, 64, time_dim, cond_dim)\n",
        "        self.down3 = ConditionalBlock(64, 128, time_dim, cond_dim)\n",
        "\n",
        "        self.bottleneck = ConditionalBlock(128, 256, time_dim, cond_dim)\n",
        "\n",
        "        self.up1 = ConditionalBlock(256 + 128, 128, time_dim, cond_dim)\n",
        "        self.up2 = ConditionalBlock(128 + 64, 64, time_dim, cond_dim)\n",
        "        self.up3 = ConditionalBlock(64 + 32, 32, time_dim, cond_dim)\n",
        "\n",
        "        self.out = nn.Conv2d(32, 3, 1)\n",
        "        self.downsample = nn.AvgPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    def forward(self, x, t, _, text_emb):\n",
        "        t_emb = self.time_mlp(t)\n",
        "        c_emb = self.cond_proj(text_emb)\n",
        "\n",
        "        d1 = self.down1(x, t_emb, c_emb)\n",
        "        d2 = self.down2(self.downsample(d1), t_emb, c_emb)\n",
        "        d3 = self.down3(self.downsample(d2), t_emb, c_emb)\n",
        "\n",
        "        b = self.bottleneck(self.downsample(d3), t_emb, c_emb)\n",
        "\n",
        "        u1 = self.up1(torch.cat([self.upsample(b), d3], dim=1), t_emb, c_emb)\n",
        "        u2 = self.up2(torch.cat([self.upsample(u1), d2], dim=1), t_emb, c_emb)\n",
        "        u3 = self.up3(torch.cat([self.upsample(u2), d1], dim=1), t_emb, c_emb)\n",
        "\n",
        "        return self.out(u3)\n",
        "\n",
        "model = ConditionalUNet().to(DEVICE)\n",
        "\n",
        "# Create model\n",
        "model = ConditionalUNet().to(DEVICE)\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMeCe5ybEuni",
        "outputId": "2ecf769d-dbcd-4ab9-ab11-cb809ab5164b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model created with 3,068,387 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6:Diffusion Utilities**"
      ],
      "metadata": {
        "id": "v9x8uUuqGqMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Diffusion:\n",
        "    def __init__(self, timesteps=500, device='cuda'):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "\n",
        "        self.betas = torch.linspace(1e-4, 0.02, timesteps, device=self.device)\n",
        "        self.alphas = 1. - self.betas\n",
        "        self.alpha_bars = torch.cumprod(self.alphas, dim=0).to(self.device)  # <— this line is crucial\n",
        "\n",
        "\n",
        "    def forward_process(self, x0, t):\n",
        "        sqrt_alpha_bar = torch.sqrt(self.alpha_bars[t])[:, None, None, None]\n",
        "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bars[t])[:, None, None, None]\n",
        "        noise = torch.randn_like(x0)\n",
        "        return sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise, noise\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def ddim_step(self, model, x, t, t_prev, text_emb, guidance_scale=5.0):\n",
        "        null_text = torch.zeros_like(text_emb).to(DEVICE)\n",
        "        noise_cond = model(x, t, None, text_emb)\n",
        "        noise_uncond = model(x, t, None, null_text)\n",
        "        noise_pred = noise_uncond + guidance_scale * (noise_cond - noise_uncond)\n",
        "\n",
        "        alpha_t = self.alpha_bars[t][:, None, None, None]\n",
        "        alpha_t_prev = self.alpha_bars[t_prev][:, None, None, None]\n",
        "\n",
        "        sqrt_alpha_t = torch.sqrt(alpha_t)\n",
        "        sqrt_alpha_t_prev = torch.sqrt(alpha_t_prev)\n",
        "\n",
        "        pred_x0 = (x - torch.sqrt(1 - alpha_t) * noise_pred) / sqrt_alpha_t\n",
        "        dir_xt = torch.sqrt(1 - alpha_t_prev) * noise_pred\n",
        "\n",
        "        x_prev = sqrt_alpha_t_prev * pred_x0 + dir_xt\n",
        "\n",
        "        return x_prev\n",
        "\n",
        "# Initialize diffusion utilities\n",
        "diffusion = Diffusion(timesteps=TIMESTEPS, device=DEVICE)\n",
        "print(f\"Diffusion process initialized with {TIMESTEPS} timesteps\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-7hiO4XGvM0",
        "outputId": "6ac45b2a-b5b5-440c-c6a3-5f2d75ea8af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diffusion process initialized with 500 timesteps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step7: Training Function**"
      ],
      "metadata": {
        "id": "Wss-8TMcHhkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_diffusion_model(model, diffusion, train_loader, num_epochs=NUM_EPOCHS, device=DEVICE):\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for imgs, labels, text_embs in progress_bar:\n",
        "            imgs = imgs.to(device)\n",
        "            text_embs = text_embs.to(device)\n",
        "\n",
        "            t = torch.randint(0, diffusion.timesteps, (imgs.size(0),), device=device).long()\n",
        "            noisy_imgs, noise = diffusion.forward_process(imgs, t)\n",
        "\n",
        "            noise_pred = model(noisy_imgs, t, None, text_embs)\n",
        "\n",
        "            loss = F.mse_loss(noise_pred, noise)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} finished | Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model\n",
        "# Start training\n",
        "print(\"Starting training...\")\n",
        "trained_model = train_diffusion_model(model, diffusion, train_loader)\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f65HA1gbHh2G",
        "outputId": "1d7985b7-759e-4f0c-ef73-30405058c524"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 782/782 [00:46<00:00, 16.86it/s, loss=0.0576]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 finished | Average Loss: 0.1203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 782/782 [00:46<00:00, 16.90it/s, loss=0.0375]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 finished | Average Loss: 0.0685\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 782/782 [00:46<00:00, 16.97it/s, loss=0.0603]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 finished | Average Loss: 0.0620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 782/782 [00:46<00:00, 16.84it/s, loss=0.0626]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished | Average Loss: 0.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 782/782 [00:46<00:00, 16.84it/s, loss=0.0681]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished | Average Loss: 0.0578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 782/782 [00:46<00:00, 16.80it/s, loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished | Average Loss: 0.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 782/782 [00:46<00:00, 16.65it/s, loss=0.0129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished | Average Loss: 0.0560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 782/782 [00:46<00:00, 16.77it/s, loss=0.022]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished | Average Loss: 0.0549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 782/782 [00:46<00:00, 16.71it/s, loss=0.0513]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished | Average Loss: 0.0538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 782/782 [00:46<00:00, 16.72it/s, loss=0.0762]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished | Average Loss: 0.0536\n",
            "Training completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Sampling and Visualization Functions**"
      ],
      "metadata": {
        "id": "IIqJj3vEmBDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_ddim(model, diffusion, num_samples=1, text_prompt=None, guidance_scale=5.0, steps=50, device='cuda'):\n",
        "    model.eval()\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "\n",
        "    if text_prompt is None:\n",
        "        text_emb = torch.zeros(num_samples, 512).to(device)\n",
        "    else:\n",
        "        inputs = tokenizer([text_prompt] * num_samples, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        text_emb = text_encoder(**inputs).last_hidden_state.mean(dim=1)\n",
        "\n",
        "    x = torch.randn(num_samples, 3, 32, 32).to(device)\n",
        "    timesteps = torch.linspace(diffusion.timesteps - 1, 0, steps).long()\n",
        "\n",
        "    for i in range(steps - 1):\n",
        "        t = timesteps[i].repeat(num_samples).to(device)\n",
        "        t_prev = timesteps[i + 1].repeat(num_samples).to(device)\n",
        "        x = diffusion.ddim_step(model, x, t, t_prev, text_emb, guidance_scale=guidance_scale)\n",
        "\n",
        "    return x.clamp(-1, 1)\n",
        "\n",
        "\n",
        "def visualize_samples(samples, title=\"Generated Samples\"):\n",
        "    samples = samples.cpu().permute(0, 2, 3, 1)\n",
        "    samples = (samples + 1) / 2\n",
        "    samples = samples.clamp(0, 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    for i in range(min(4, samples.shape[0])):\n",
        "        plt.subplot(1, 4, i + 1)\n",
        "        plt.imshow(samples[i])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def save_images(samples, folder=\"generated_images\"):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    for i, img in enumerate(samples):\n",
        "        img_path = f\"{folder}/sample_{i}.png\"\n",
        "        img_pil = transforms.ToPILImage()((img.cpu() + 1) / 2)\n",
        "        img_pil.save(img_path)\n",
        "    print(f\"Saved {len(samples)} images to {folder}\")\n",
        "\n",
        "\n",
        "def evaluate_fid_is(generated_dir, real_dir=\"./data/cifar10_png\"):\n",
        "    metrics = calculate_metrics(\n",
        "        input1=generated_dir,\n",
        "        input2=real_dir,\n",
        "        cuda=torch.cuda.is_available(),\n",
        "        isc=True,\n",
        "        fid=True,\n",
        "        kid=False\n",
        "    )\n",
        "    print(\"FID:\", metrics['frechet_inception_distance'])\n",
        "    print(\"Inception Score:\", metrics['inception_score_mean'])\n",
        "    return metrics\n",
        "\n",
        "\n",
        "device_clip = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device_clip)\n",
        "\n",
        "\n",
        "def compute_clipscore(image_tensor, prompt):\n",
        "    image = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    image = ((image + 1) * 127.5).astype(np.uint8)\n",
        "    pil_image = Image.fromarray(image)\n",
        "    image_input = clip_preprocess(pil_image).unsqueeze(0).to(device_clip)\n",
        "    text_input = clip.tokenize([prompt]).to(device_clip)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_features = clip_model.encode_image(image_input)\n",
        "        text_features = clip_model.encode_text(text_input)\n",
        "\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    similarity = (image_features @ text_features.T).item()\n",
        "    return similarity\n",
        "\n",
        "\n",
        "def batch_clipscore(samples, prompt):\n",
        "    scores = []\n",
        "    for i in range(samples.shape[0]):\n",
        "        scores.append(compute_clipscore(samples[i], prompt))\n",
        "    avg_score = np.mean(scores)\n",
        "    print(f\"Average CLIPScore for prompt '{prompt}': {avg_score:.4f}\")\n",
        "    return avg_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCGDCIG_I8PA",
        "outputId": "98a09573-c8af-4cc3-a8cf-c4ffcc0fcaf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:24<00:00, 14.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9:Experiment Workflow**"
      ],
      "metadata": {
        "id": "DBbWV8PxefiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate images\n",
        "samples = sample_ddim(trained_model, diffusion, num_samples=8, text_prompt=\"a red car with mountain background\", guidance_scale=7.5)\n",
        "\n",
        "# Visualize\n",
        "visualize_samples(samples, title=\"Generated Images: Red Car with Mountain\")\n",
        "\n",
        "# Save images\n",
        "save_images(samples, folder=\"generated_images\")\n",
        "\n",
        "# Evaluate CLIPScore\n",
        "batch_clipscore(samples, prompt=\"a red car with mountain background\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "za905UH1JvVn",
        "outputId": "609d8ec0-c6b1-4092-95ac-dbcac20f1a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 8 images to generated_images\n",
            "Average CLIPScore for prompt 'a red car with mountain background': 0.1846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.1845703125)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = sample_ddim(trained_model, diffusion, num_samples=8, text_prompt=\"an automobile on the road\", guidance_scale=7.5)\n",
        "visualize_samples(samples, title=\"Generated Images: Automobile on Road\")\n",
        "batch_clipscore(samples, \"an automobile on the road\")\n"
      ],
      "metadata": {
        "id": "hHlyH3qDLe6r",
        "outputId": "743ebb15-51c9-4867-e4c6-6096c5d748a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average CLIPScore for prompt 'an automobile on the road': 0.2038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.2037811279296875)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}